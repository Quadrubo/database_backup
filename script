#!/usr/bin/python3.9
import subprocess
import os
import json
from datetime import datetime

JSON_FILE_NAME = "/boot/config/plugins/user.scripts/scripts/database_backup/containers.json"
TMP_FOLDER = "/boot/config/plugins/user.scripts/scripts/database_backup/tmp"
OUTPUT_FOLDER = "/mnt/user/database_backups"

with open(JSON_FILE_NAME, 'r') as f:
    container_json = json.load(f)["containers"]

if not os.path.exists(TMP_FOLDER):
    os.mkdir(TMP_FOLDER)

if not os.path.exists(OUTPUT_FOLDER):
    os.mkdir(OUTPUT_FOLDER)

file_names = []

def get_database_list_from_mysql(container_name, root_password):
    command = f"echo 'show databases;' | docker exec -i {container_name} mysql --user=root --password={root_password} | grep -v Database | grep -v information_schema | grep -v mysql | grep -v performance_schema"

    return subprocess.check_output(command, shell=True).decode("utf-8").splitlines()

def get_database_list(container_name, database_type, root_password):
    if database_type in ["mariadb"]:
        return get_database_list_from_mysql(container_name, root_password)

    raise ValueError(f"Unknown database type \"{database_type}\".")

def dump_database_to_sql_from_mysql(container_name, root_password):
    dump_command = f"docker exec {container_name} mysqldump -u root -p{root_password} {database} > {TMP_FOLDER}/{container_name}_{database}.sql"

    sql_dumper = subprocess.Popen(dump_command, stdout=subprocess.PIPE, shell=True)
    sql_dumper.wait()

    return f"{TMP_FOLDER}/{container_name}_{database}.sql"

def dump_database_to_sql(container_name, database_type, root_password):
    if database_type in ["mariadb"]:
        return dump_database_to_sql_from_mysql(container_name, root_password)

    raise ValueError(f"Unknown database type \"{database_type}\".")

def gzip_sql_files(files):
    output_file_name = datetime.now().strftime("%Y-%m-%dT%H-%M-%S") + "_db_backup.tar.gz"

    command = f"tar --remove-files -czf {OUTPUT_FOLDER}/{output_file_name} " + " ".join(files)

    p = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)
    p.wait()

    print(f"Database backup written to \"{OUTPUT_FOLDER}/{output_file_name}\".")

for container in container_json:
    container_name = container["container_name"]
    database_type = container["database_type"]
    root_password = container["root_password"]

    databases = get_database_list(container_name, database_type, root_password)

    for database in databases:
        sql_file_name = dump_database_to_sql(container_name, database_type, root_password)

        file_names.append(sql_file_name)

gzip_sql_files(file_names)